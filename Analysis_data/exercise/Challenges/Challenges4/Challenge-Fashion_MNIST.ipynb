{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lg2hLK7hlWdb"
   },
   "source": [
    "# Clasificando Fashion-MNIST\n",
    "\n",
    "Ahora es su turno de construir y entrenar una red neuronal. Utilizará el [Fashion-MNIST dataset](https://github.com/zalandoresearch/fashion-mnist), un reemplazo al MNIST dataset. MNIST es en realidad bastante trivial con las redes neuronales en las que puede lograr fácilmente una precisión superior al 97%. Fashion-MNIST es un conjunto de imágenes de ropa en escala de grises de 28x28. Es más complejo que MNIST, por lo que es una mejor representación del rendimiento real de su red y una mejor representación de los conjuntos de datos que utilizará en el mundo real.\n",
    "\n",
    "<img src='assets/fashion-mnist-sprite.png' width=500px>\n",
    "\n",
    "En este cuaderno, creará su propia red neuronal. En su mayor parte, podría simplemente copiar y pegar el código de la Parte 3, pero no estaría aprendiendo. Es importante que usted mismo escriba el código y lo haga funcionar. No dude en consultar los cuadernos anteriores mientras trabaja en esto.\n",
    "\n",
    "\n",
    "En primer lugar, importemos nuestros recursos y descarguemos el conjunto de datos Fashion-MNIST de `tensorflow_datasets`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EMflYTIOtOPf"
   },
   "source": [
    "## Importar recursos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BjSLR8Ri6ERa"
   },
   "outputs": [],
   "source": [
    "#importe el paquete de warnings     https://docs.python.org/es/3/library/warnings.html \n",
    "\n",
    "#\n",
    "#warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U0n2QWj1p2fG"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'          #https://ryanwingate.com/visualization/matplotlib/inline-backend-on-retina-displays/\n",
    "\n",
    "#importe numpy\n",
    "#importe pyplot de matplotlib\n",
    "\n",
    "#importe tensorflow\n",
    "\n",
    "#importe datasets de tensorflow\n",
    "\n",
    "#Muestre una barra de progreso de las epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rrD1O5Q56ERd"
   },
   "outputs": [],
   "source": [
    "#import logging para mostrar que esta sucediendo, \n",
    "\n",
    "\n",
    "#instancialo y \n",
    "\n",
    "\n",
    "#establece el nivel del logger (que tipo de mensajes va a mostrar)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FwP1_Qw-cCsY"
   },
   "outputs": [],
   "source": [
    "#imprima la version de TensorFlow\n",
    "\n",
    "\n",
    "#imprima la version de Keras\n",
    "\n",
    "\n",
    "#Imprima si esta disponible una GPU para correr TensorFlow sobre esta, en caso contrario que tambien lo indique\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vr2SOjl8txrZ"
   },
   "source": [
    "## Cargar el conjunto de datos\n",
    "\n",
    "Ahora vamos a cargar el conjunto de datos Fashion-MNIST usando `tensorflow_datasets` como ya lo hemos hecho. En este caso, sin embargo, vamos a omitir el argumento \"split\".  Esto significa queusará el valor predeterminado para` split` que es `split = None`. Cuando `split=None`, el `tensorflow_datasets` regresa un **dictionario** con todas las divisiones disponibles para el conjunto de datos que estás cargando. Sin embargo, si la división se da explícitamente, como `split='train'`, entonces `tensorflow_datasets` regresa un objeto `tf.data.Dataset`.\n",
    "\n",
    "En nuestro caso, vamos a cargar el conjunto de datos `fashion_mnist`. Si miramos la [documentación](https://www.tensorflow.org/datasets/catalog/fashion_mnist#statistics) veremos que este conjunto de datos en particular tiene 2 divisiones, la de entrenamiento (`train`) y la de prueba (`test`). También vemos que la división `train` tiene 60,000 ejemplos y que la división` test` tiene 10,000 ejemplos.\n",
    "\n",
    "Ahora, carguemos el conjunto de datos `fashion_mnist` e inspeccionemos los valores devueltos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1kn4Op7dXCnk"
   },
   "outputs": [],
   "source": [
    "#Cargue el dataset de fashion_MNIST y la informacion de este mismo en su forma \"as_supervised = True\"            #https://www.tensorflow.org/datasets/api_docs/python/tfds/load\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2_vT6HUUXg05"
   },
   "outputs": [],
   "source": [
    "# Checar que el dataset es de typo dictionario\n",
    "\n",
    "\n",
    "# Imprimir las keys del dataset (dictionary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6S4f2J9jbpak"
   },
   "source": [
    "En la celda de abajo, vamos a guardar los datos de entrenamiento y los datos de prueba en diferentes variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kxo7PHJys18t"
   },
   "outputs": [],
   "source": [
    "#asignar a los datos del training_set y de test_set su contenido respectivo\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzZciG_KcHbI"
   },
   "source": [
    "Ahora, echemos un vistazo al `dataset_info`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7jFE3vbebU-A"
   },
   "outputs": [],
   "source": [
    "# Display la dataset_info\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0_If36cti685"
   },
   "source": [
    "Podemos acceder a la información en `dataset_info` muy fácilmente. Como podemos ver, la información de `features` y` splits` está contenida en diccionarios. Podemos acceder a la información que queremos accediendo a la clave y el valor particulares en estos diccionarios. Comenzamos mirando los valores de claves particulares en estos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6KtD7j5HgTkn"
   },
   "outputs": [],
   "source": [
    "#Veamos la forma (shape) y el dtype de 'image' contenido en 'features' dentro del diccionario\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l_QXhcTOiQ1a"
   },
   "outputs": [],
   "source": [
    "#Veamos la forma, el dtype y sus num_classes de 'label' contenido en 'features' dentro del diccionario\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gGn6yzTxgKwj"
   },
   "outputs": [],
   "source": [
    "#Accedamos a num_examples de 'train' contenido en 'splits' dentro del diccionario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MFwhpPOijumG"
   },
   "source": [
    "Ahora podemos usar la notación de puntos para acceder a la información que queremos. A continuación se muestran algunos ejemplos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m9_OYPHsbbcl"
   },
   "outputs": [],
   "source": [
    "#asignemos a una variable la shape de 'image'\n",
    "shape_images =\n",
    "\n",
    "#asignemos a una variable las num_classes de 'label'\n",
    "num_classes = \n",
    "\n",
    "#asignemos a una variable las num_examples de 'train' contenido en 'splits' \n",
    "num_training_examples =\n",
    "\n",
    "#asignemos a una variable las num_examples de 'test' contenido en 'splits' \n",
    "num_test_examples =\n",
    "\n",
    "\n",
    "\n",
    "#Mostremos un mensaje en pantalla con el numero de clases y la forma que tiene el dataset\n",
    "\n",
    "print('...'.format(...))\n",
    "print('...', ...)\n",
    "\n",
    "\n",
    "#Mostremos un mensaje en pantalla con el numero de imagenes contenidas en los conjuntos de entrenamiento y prueba\n",
    "print('\\nThere are {:,} images in the test set'.format(...))\n",
    "print('There are {:,} images in the training set'.format(...))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfMgIb3PvWXo"
   },
   "source": [
    "## Explore el conjunto de datos\n",
    "\n",
    "Las imágenes de este conjunto de datos son matrices de 28 $\\times$ 28 con valores de píxeles en el rango de ` [0, 255] `. Las *etiquetas* (*labels*) son una matriz de números enteros, en el rango \"[0, 9]\". Estos corresponden a la *clase* (*class*) de ropa que representa la imagen:\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Label</th>\n",
    "    <th>Class</th> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>0</td>\n",
    "    <td>T-shirt/top</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>Trouser</td> \n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>2</td>\n",
    "    <td>Pullover</td> \n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>3</td>\n",
    "    <td>Dress</td> \n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>4</td>\n",
    "    <td>Coat</td> \n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>5</td>\n",
    "    <td>Sandal</td> \n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>6</td>\n",
    "    <td>Shirt</td> \n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>7</td>\n",
    "    <td>Sneaker</td> \n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>8</td>\n",
    "    <td>Bag</td> \n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>9</td>\n",
    "    <td>Ankle boot</td> \n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "Cada imagen se asigna a una sola etiqueta. Dado que los * nombres de clase * no están incluidos con el conjunto de datos, los creamos aquí para usarlos más adelante al trazar las imágenes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "odzN3aJjusED"
   },
   "outputs": [],
   "source": [
    "#creemos la lista del total de clases\n",
    "class_names = ['...']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RoY1HeJJyces"
   },
   "outputs": [],
   "source": [
    "#Mostramos el 'dtype' y el 'shape' de un elemento del conjunto de datos de entrenamiento con ayuda de un ciclo for\n",
    "for ..., ... in ... :                                                                                           #HINT: https://www.tensorflow.org/tutorials/load_data/text\n",
    "    print('The images in the training set have:\\n\\u2022 dtype:', image.dtype, '\\n\\u2022 shape:', image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CInprnnJ1_gk"
   },
   "outputs": [],
   "source": [
    "#Similar al anterior, ahora asigna a las variables 'image' y 'label'  el contenido de ese elemento convirtiendo\n",
    "for ..., ... in ... :\n",
    "    image = ...                                                                                                  #HINT: https://numpy.org/doc/stable/reference/generated/numpy.squeeze.html\n",
    "    label = ...\n",
    "\n",
    "\n",
    "#imprimir en una la imagen del elemento \n",
    "plt.imshow(..., cmap= plt.cm.binary)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#mostrar la etiqueta de esa imagen\n",
    "print('The label of this image is:', ...)\n",
    "#mostrar la clase de la etiqueta de esa imagen\n",
    "print('The class name of this image is:', ...[...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hb-lmuTM35C9"
   },
   "source": [
    "## Crear Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3gq-_mXl3ZFG"
   },
   "outputs": [],
   "source": [
    "def normalize(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255\n",
    "    return image, label\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "training_batches = training_set.cache().shuffle(num_training_examples//4).batch(batch_size).map(normalize).prefetch(1)\n",
    "testing_batches = test_set.cache().batch(batch_size).map(normalize).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LviX4-ii8js7"
   },
   "source": [
    "## Construir el modelo\n",
    "> **Ejercicio:** Aquí debes definir tu propia red neuronal. Siéntase libre de crear un modelo con tantas capas y neuronas como desee. Debe tener en cuenta que, al igual que con MNIST, cada imagen es 28 $\\times$ 28 which is a total of 784 pixels, y hay 10 clases. Su modelo debe incluir al menos una capa oculta. Le sugerimos que utilice las funciones de activación de ReLU para las capas ocultas y una función de activación softmax para la capa de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OYzFZ3jQ8azd"
   },
   "outputs": [],
   "source": [
    "## Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CYhwsFzA-Aah"
   },
   "source": [
    "## Entrenar al modelo\n",
    "> **Ejercicio:** Compile el modelo que creó anteriormente usando un optimizador `adam`, una función de pérdida` sparse_categorical_crossentropy` y la métrica de `precisión` (`accuracy` ). Luego entrena el modelo durante 5 épocas. Debería poder obtener la pérdida de entrenamiento (training loss) por debajo de 0.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cyy9SqTU91IS"
   },
   "outputs": [],
   "source": [
    "## Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "REJbwplUBoRT"
   },
   "source": [
    "## Evaluar la pérdida y la precisión en el conjunto de prueba\n",
    "\n",
    "Ahora veamos cómo funciona el modelo en el conjunto de prueba (`test set`). Esta vez, usaremos todos los ejemplos en nuestro conjunto de prueba para evaluar la pérdida (`loss`) y precisión de nuestro modelo (`accuracy`). Recuerde, las imágenes de la prueba son imágenes que el modelo nunca ha visto antes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q76aDGGl_xp4"
   },
   "outputs": [],
   "source": [
    "loss, accuracy = my_model. ...(...) #evaluemos\n",
    "\n",
    "print('\\nLoss on the TEST Set: {:,.3f}'.format(...))  #perdida\n",
    "print('Accuracy on the TEST Set: {:.3%}'.format(...)) #precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PnpZWDQp2Zaq"
   },
   "source": [
    "## Validar Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kqUzc4pYAe7Z"
   },
   "outputs": [],
   "source": [
    "for image_batch, label_batch in testing_batches.take(1):\n",
    "    ps = my_model.predict(image_batch)\n",
    "    first_image = image_batch.numpy().squeeze()[0]\n",
    "    first_label = label_batch.numpy()[0]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "ax1.imshow(first_image, cmap = plt.cm.binary)\n",
    "ax1.axis('off')\n",
    "ax1.set_title(class_names[first_label])\n",
    "ax2.barh(np.arange(10), ps[0])\n",
    "ax2.set_aspect(0.1)\n",
    "ax2.set_yticks(np.arange(10))\n",
    "ax2.set_yticklabels(class_names, size='small');\n",
    "ax2.set_title('Class Probability')\n",
    "ax2.set_xlim(0, 1.1)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gs6wGo79So1E"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Challenge-Fashion_MNIST.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
